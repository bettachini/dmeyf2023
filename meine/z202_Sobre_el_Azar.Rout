
R version 4.2.2 Patched (2022-11-10 r83330) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ## Sobre el Azar
> ##
> ## ---------------------------
> ## Step 1: El simple y viejo Train / Test
> ## ---------------------------
> ##
> ## If you torture the data long enough, it will confess.
> ## --- Ronald Coase
> ##
> 
> # nolint: indentation_linter.
> 
> # Limpiamos el entorno
> rm(list = ls())
> gc(verbose = FALSE)
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 273777 14.7     661174 35.4   452247 24.2
Vcells 459277  3.6    8388608 64.0  1801102 13.8
> 
> # Librerías necesarias
> # require("data.table")
> # require("rpart")
> # require("ROCR")
> # require("ggplot2")
> 
> 
> # Poner la carpeta de la materia de SU computadora local
> base = '/home/vbettachini/documents/universitet/FCEyN/maestríaDatos/economíaFinanzas/dmeyf2023/meine/'
> setwd(base)
> # Poner sus semillas
> semillas <- c(777787, 274837, 874807, 674831, 974821)
> 
> # Cargamos el dataset
> if(!require('data.table')){
+     install.packages('data.table')
+ }
Loading required package: data.table
> library('data.table')
> dataset <- fread("./competencia_01.csv")
> 
> # Nos quedamos solo con el 202101
> dataset <- dataset[foto_mes == 202103]
> # Creamos una clase binaria
> dataset[, clase_binaria := ifelse(
+                             clase_ternaria == "BAJA+2",
+                                 "evento",
+                                 "noevento"
+                             )]
> # Borramos el target viejo
> dataset[, clase_ternaria := NULL]
> 
> # Seteamos nuestra primera semilla
> set.seed(semillas[1])
> 
> # Particionamos de forma estratificada
> if(!require('caret')){
+     install.packages('caret')
+ }
Loading required package: caret
Loading required package: ggplot2
Loading required package: lattice
> library('caret')
> 
> in_training <- caret::createDataPartition(dataset$clase_binaria,
+                      p = 0.70, list = FALSE) 
> dtrain  <-  dataset[in_training, ]
> dtest   <-  dataset[-in_training, ]
> 
> ## Preguntas
> ## - ¿Por qué separamos en train/test?
> ## - Son números aleatorios los que nos dan las computadoras
> ## - ¿Por qué usamos semillas?
> ## - ¿Qué es una partición estratificada?
> ## - ¿Tiene realemente alguna ventaja la partición estratificada ?
> 
> ## ---------------------------
> ## Step 2: Armando el primer modelo particionado
> ## ---------------------------
> 
> # Medimos cuanto tarda nuestro modelo en ajustar
> if(!require('rpart')){
+     install.packages('rpart')
+ }
Loading required package: rpart
> library('rpart')
> 
> start_time <- Sys.time()
> modelo <- rpart(clase_binaria ~ .,
+                 data = dtrain,
+                 xval = 0,
+                 cp = 0,
+                 minsplit = 20,
+                 minbucket = 1,
+                 maxdepth = 5)
> print(Sys.time() - start_time)
Time difference of 7.95371 secs
> 
> pred_testing <- predict(modelo, dtest, type = "prob")
> 
> ## Preguntas:
> ## - ¿Qué tan importante mirar las métricas de train?
> 
> ## ---------------------------
> ## Step 3: Mirando la ganancia
> ## ---------------------------
> 
> # Armamos una función que nos calcule la ganancia, usando el punto de corte de
> # 0.025
> ganancia <- function(probabilidades, clase) {
+   return(sum(
+     (probabilidades >= 0.025) * ifelse(clase == "evento", 273000, -7000))
+   )
+ }
> 
> # La ganancia en testing NORMALIZADA
> print(ganancia(pred_testing[, "evento"], dtest$clase_binaria) / 0.3)
[1] 52616667
> 
> ## Actividad:
> ## Comparta el número que le dio de ganancia y cuanto error estima que
> ## puede haber con el resto de sus compañeros
> 
> ## ---------------------------
> ## Step 4: Probando más muchas más semillas
> ## ---------------------------
> 
> # Almacenaremos los resultados en una tabla
> resultados_n_gan <- c()
> 
> # Calcule en función del tiempo de ejecución anterior, cuantos árboles puede
> # hacer en 5 minutos y ponga ese número en la siguiente variable
> n <- 100
> 
> set.seed(semillas[1])
> t0 <- Sys.time()
> for (i in 1:n) {
+ 
+     in_training <- caret::createDataPartition(dataset[, get("clase_binaria")],
+                             p = 0.70, list = FALSE)
+     dtrain  <-  dataset[in_training, ]
+     dtest   <-  dataset[-in_training, ]
+ 
+     modelo <- rpart(clase_binaria ~ .,
+                     data = dtrain,
+                     xval = 0,
+                     cp = 0,
+                     minsplit = 20,
+                     minbucket = 1,
+                     maxdepth = 5)
+ 
+     pred_testing <- predict(modelo, dtest, type = "prob")
+ 
+     gan <- ganancia(pred_testing[, "evento"], dtest$clase_binaria) / 0.3
+ 
+     resultados_n_gan <- c(resultados_n_gan, gan)
+ }
> print(Sys.time() - t0)
Time difference of 12.90581 mins
> 
> ## Preguntas:
> ## ¿Cree que puede cambiar mucho la ganancia en **test** para dos semillas
> ## distintas?
> 
> ## ---------------------------
> ## Step 5: Analizando el azar de las semillas
> ## ---------------------------
> 
> # La menor ganancia conseguida en test
> print(min(resultados_n_gan))
[1] 38383333
> 
> # La mayor ganancia
> print(max(resultados_n_gan))
[1] 66056667
> 
> # La media de la ganancia
> print(mean(resultados_n_gan))
[1] 52378667
> 
> # Veamos la dispersión de la ganancia
> if(!require('ggplot2')){
+     install.packages('ggplot2')
+ }
> library('ggplot2')
> 
> ggplot() + aes(resultados_n_gan) + geom_density()
> 
> ## Preguntas
> ## Buscamos separar los conjuntos de datos para hacer robustos nuestros modelos
> ## y nos damos cuenta que las `semillas` pueden distorsionar enormemente 
> ## las métricas reales (si es que existen).
> ## - ¿Por qué se produce semejante dispersión?
> ## - ¿Cuál considera que es el "valor real"?
> ## 
> ##   Dicho de otra forma, si aplicara el mismo modelo a un nuevo conjunto de 
> ##   datos, ¿cuál sería el esperado?
> 
> ## ---------------------------
> ## Step 6: Tratando de corregir la dispersión
> ## ---------------------------
> 
> # Veamos si tomar el promedio de 5 árboles nos ayuda a reducir la dispersión
> cantidad_arboles <- 5
> 
> resultados_n_mcv <- c()
> set.seed(semillas[1])
> 
> for (i in 1:50) 
+     resultados_n_mcv <- c(resultados_n_mcv, mean(sample(resultados_n_gan, cantidad_arboles)))
> 
> # La menor ganancia conseguida en test
> print(min(resultados_n_mcv))
[1] 47464667
> 
> # La mayor ganancia
> print(max(resultados_n_mcv))
[1] 57236667
> 
> # La media de la ganancia
> print(mean(resultados_n_mcv))
[1] 52733613
> 
> # Veamos la dispersión de la ganancia
> ggplot() + aes(resultados_n_mcv) + geom_density()
> 
> ## NOTA: Esta técnica es conocida como Montecarlo Cross Validation
> ##
> ## Preguntas
> ## - ¿Qué efecto observa cuando se toma como medición el promedio de 5 árboles?
> ## - ¿Desapareció el error?
> ## - ¿Si se hubieran tomado más valores que efectos esperaría?
> ## - ¿Que ventaja y desventaja ve en esta técnica comparada al Cross Validation?
> 
> ## ---------------------------
> ## Step 7: Midiendo nuestras semillas
> ## ---------------------------
> 
> resultados_mis_semillas <- c()
> 
> t0 <- Sys.time()
> for (s in semillas) {
+     set.seed(s)
+     in_training <- caret::createDataPartition(dataset[, get("clase_binaria")],
+                             p = 0.70, list = FALSE)
+     dtrain  <-  dataset[in_training, ]
+     dtest   <-  dataset[-in_training, ]
+ 
+     modelo <- rpart(clase_binaria ~ .,
+                     data = dtrain,
+                     xval = 0,
+                     cp = 0,
+                     minsplit = 20,
+                     minbucket = 1,
+                     maxdepth = 5)
+ 
+     pred_testing <- predict(modelo, dtest, type = "prob")
+ 
+     gan <- ganancia(pred_testing[, "evento"], dtest$clase_binaria) / 0.3
+ 
+     resultados_mis_semillas <- c(resultados_mis_semillas, gan)
+ 
+ }
> print(Sys.time() - t0)
Time difference of 38.47754 secs
> 
> print(mean(resultados_mis_semillas))
[1] 47702667
> 
> ## Preguntas
> ## - ¿Cuán lejos se encontró la media de sus semillas respecto a los resultados
> ##    anteriores?
> ## - ¿Usaría semillas que le den un valor promedio más alto?
> ## - ¿Usaría más semillas?
> ## - ¿Que ventaja y desventaja ve en usar más semillas?
> 
> ## ---------------------------
> ## Step 8: Buscando un mejor modelo
> ## ---------------------------
> 
> resultados_grid_search <- data.table()
> 
> # Complete los valores que se van a combinar para cada parámetro a explorar
> 
> for (cp in c(-1, 0.01)) { 
+ for (md in c(5, 10, 15, 30)) {
+ for (ms in c(1, 50, 500, 1000)) {
+ for (mb in c(1, as.integer(ms / 2))) {
+ 
+     t0 <- Sys.time()
+     gan_semillas <- c()
+     for (s in semillas) {
+         set.seed(s)
+         in_training <- caret::createDataPartition(dataset[,
+                         get("clase_binaria")],
+                                 p = 0.70, list = FALSE)
+         dtrain  <-  dataset[in_training, ]
+         dtest   <-  dataset[-in_training, ]
+ 
+         modelo <- rpart(clase_binaria ~ .,
+                         data = dtrain,
+                         xval = 0,
+                         cp = cp,
+                         minsplit = ms,
+                         minbucket = mb,
+                         maxdepth = md)
+ 
+         pred_testing <- predict(modelo, dtest, type = "prob")
+         gan <- ganancia(pred_testing[, "evento"], dtest$clase_binaria) / 0.3
+ 
+         gan_semillas <- c(gan_semillas, gan)
+     }
+     tiempo <-  as.numeric(Sys.time() - t0, units = "secs")
+ 
+     resultados_grid_search <- rbindlist(list(
+                                 resultados_grid_search,
+                                 data.table(
+                                     tiempo = tiempo,
+                                     cp = cp,
+                                     mb = mb,
+                                     ms = ms,
+                                     md = md,
+                                     gan = mean(gan_semillas)) # se puede agregar el sd?
+                                 ))
+ }
+ }
+ }
+ }
> 
> 
> # Graba un archivo
> saveRDS(object= resultados_grid_search, file= './resultados_grid_search.rds')
> 
> # Visualizo los parámetros de los mejores parámetros
> print(resultados_grid_search[gan == max(gan), ])
     tiempo cp  mb   ms md      gan
1: 39.97358 -1 500 1000  5 65828000
> resultados_grid_search
       tiempo    cp  mb   ms md      gan
 1:  38.56969 -1.00   1    1  5 49415333
 2:  38.39891 -1.00   0    1  5 49415333
 3:  38.30656 -1.00   1   50  5 49392000
 4:  39.53011 -1.00  25   50  5 60162667
 5:  38.49204 -1.00   1  500  5 49434000
 6:  39.87419 -1.00 250  500  5 63420000
 7:  38.38406 -1.00   1 1000  5 49298667
 8:  39.97358 -1.00 500 1000  5 65828000
 9:  70.73801 -1.00   1    1 10 59448667
10:  70.88151 -1.00   0    1 10 59448667
11:  70.52793 -1.00   1   50 10 59532667
12:  70.58565 -1.00  25   50 10 41010667
13:  70.60142 -1.00   1  500 10 60274667
14:  68.24317 -1.00 250  500 10 60414667
15:  69.21219 -1.00   1 1000 10 60517333
16:  63.91729 -1.00 500 1000 10 64120000
17:  98.31313 -1.00   1    1 15 50708000
18:  97.81634 -1.00   0    1 15 50708000
19:  96.57248 -1.00   1   50 15 50498000
20:  90.48042 -1.00  25   50 15 23720667
21:  95.00060 -1.00   1  500 15 55552000
22:  73.47547 -1.00 250  500 15 58851333
23:  94.50930 -1.00   1 1000 15 57992667
24:  64.86070 -1.00 500 1000 15 64120000
25: 127.19620 -1.00   1    1 30 23268000
26: 127.07290 -1.00   0    1 30 23268000
27: 126.69897 -1.00   1   50 30 25610667
28:  98.85528 -1.00  25   50 30 16230667
29: 123.61966 -1.00   1  500 30 46578000
30:  73.09032 -1.00 250  500 30 58851333
31: 120.91846 -1.00   1 1000 30 51636667
32:  65.60543 -1.00 500 1000 30 64120000
33:  36.08522  0.01   1    1  5        0
34:  35.93898  0.01   0    1  5        0
35:  36.37875  0.01   1   50  5        0
36:  36.71391  0.01  25   50  5        0
37:  36.30497  0.01   1  500  5        0
38:  37.50091  0.01 250  500  5        0
39:  35.83167  0.01   1 1000  5        0
40:  37.30601  0.01 500 1000  5        0
41:  55.22698  0.01   1    1 10        0
42:  54.53545  0.01   0    1 10        0
43:  54.34606  0.01   1   50 10        0
44:  47.14971  0.01  25   50 10        0
45:  55.11902  0.01   1  500 10        0
46:  44.14515  0.01 250  500 10        0
47:  54.64649  0.01   1 1000 10        0
48:  43.42097  0.01 500 1000 10        0
49:  61.98467  0.01   1    1 15        0
50:  61.57158  0.01   0    1 15        0
51:  62.13129  0.01   1   50 15        0
52:  47.39371  0.01  25   50 15        0
53:  62.02139  0.01   1  500 15        0
54:  44.28967  0.01 250  500 15        0
55:  61.58636  0.01   1 1000 15        0
56:  43.64317  0.01 500 1000 15        0
57:  63.03353  0.01   1    1 30        0
58:  63.28148  0.01   0    1 30        0
59:  63.45030  0.01   1   50 30        0
60:  48.02788  0.01  25   50 30        0
61:  63.63116  0.01   1  500 30        0
62:  44.36542  0.01 250  500 30        0
63:  62.75468  0.01   1 1000 30        0
64:  43.32927  0.01 500 1000 30        0
       tiempo    cp  mb   ms md      gan
> 
> ## TAREA:
> ## Una vez que tenga sus mejores parámetros, haga una copia del script
> ## rpart/z101_PrimerModelo.R, cambie los parámetros dentro del script,
> ## ejecutelo y suba a Kaggle su modelo.
> 
> ## Preguntas
> ## - ¿Cuál es la diferencia entre **test** y **validation**?
> ## - ¿Cuántas veces podemos usar el conjunto de **test** sin
> ##   convertirlo en **validation**?
> ##
> ## La GRAN pregunta:
> ## - ¿Qué otra cosita de la materia tiene una partición 70 / 30?
> ## - Todo lo que hemos visto ¿Va a afectar a esa cosita?.
> 
> proc.time()
    user   system  elapsed 
4854.804  147.775 4864.447 
